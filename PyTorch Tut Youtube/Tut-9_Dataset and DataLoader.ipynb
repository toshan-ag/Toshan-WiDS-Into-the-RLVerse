{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the context of neural networks, an epoch refers to one complete pass through the entire training dataset during the training phase of \n",
    "# the network. During each epoch, the neural network processes the entire training dataset, calculates the error (the difference between the \n",
    "# predicted output and the actual output), and updates its weights to improve its performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.4230e+01, 1.7100e+00, 2.4300e+00, 1.5600e+01, 1.2700e+02, 2.8000e+00,\n",
      "        3.0600e+00, 2.8000e-01, 2.2900e+00, 5.6400e+00, 1.0400e+00, 3.9200e+00,\n",
      "        1.0650e+03]) tensor([1.])\n",
      "tensor([[1.2290e+01, 1.4100e+00, 1.9800e+00, 1.6000e+01, 8.5000e+01, 2.5500e+00,\n",
      "         2.5000e+00, 2.9000e-01, 1.7700e+00, 2.9000e+00, 1.2300e+00, 2.7400e+00,\n",
      "         4.2800e+02],\n",
      "        [1.2770e+01, 2.3900e+00, 2.2800e+00, 1.9500e+01, 8.6000e+01, 1.3900e+00,\n",
      "         5.1000e-01, 4.8000e-01, 6.4000e-01, 9.9000e+00, 5.7000e-01, 1.6300e+00,\n",
      "         4.7000e+02],\n",
      "        [1.2080e+01, 2.0800e+00, 1.7000e+00, 1.7500e+01, 9.7000e+01, 2.2300e+00,\n",
      "         2.1700e+00, 2.6000e-01, 1.4000e+00, 3.3000e+00, 1.2700e+00, 2.9600e+00,\n",
      "         7.1000e+02],\n",
      "        [1.3770e+01, 1.9000e+00, 2.6800e+00, 1.7100e+01, 1.1500e+02, 3.0000e+00,\n",
      "         2.7900e+00, 3.9000e-01, 1.6800e+00, 6.3000e+00, 1.1300e+00, 2.9300e+00,\n",
      "         1.3750e+03]]) tensor([[2.],\n",
      "        [3.],\n",
      "        [2.],\n",
      "        [1.]])\n",
      "178 45\n",
      "Epoch: 1/2, Step 5/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 1/2, Step 10/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 1/2, Step 15/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 1/2, Step 20/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 1/2, Step 25/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 1/2, Step 30/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 1/2, Step 35/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 1/2, Step 40/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 1/2, Step 45/45| Inputs torch.Size([2, 13]) | Labels torch.Size([2, 1])\n",
      "Epoch: 2/2, Step 5/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 2/2, Step 10/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 2/2, Step 15/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 2/2, Step 20/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 2/2, Step 25/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 2/2, Step 30/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 2/2, Step 35/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 2/2, Step 40/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 2/2, Step 45/45| Inputs torch.Size([2, 13]) | Labels torch.Size([2, 1])\n",
      "torch.Size([3, 1, 28, 28]) torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "# gradient computation etc. not efficient for whole data set\n",
    "# -> divide dataset into small batches\n",
    "\n",
    "'''\n",
    "# training loop\n",
    "for epoch in range(num_epochs):\n",
    "    # loop over all batches\n",
    "    for i in range(total_batches):\n",
    "        batch_x, batch_y = ...\n",
    "'''\n",
    "\n",
    "# epoch = one forward and backward pass of ALL training samples\n",
    "# batch_size = number of training samples used in one forward/backward pass\n",
    "# number of iterations = number of passes, each pass (forward+backward) using [batch_size] number of sampes\n",
    "# e.g : 100 samples, batch_size=20 -> 100/20=5 iterations for 1 epoch\n",
    "\n",
    "# --> DataLoader can do the batch computation for us\n",
    "\n",
    "# Implement a custom Dataset:\n",
    "# inherit Dataset\n",
    "# implement __init__ , __getitem__ , and __len__\n",
    "\n",
    "class WineDataset(Dataset):\n",
    "\n",
    "    def __init__(self):\n",
    "        # Initialize data, download, etc.\n",
    "        # read with numpy or pandas\n",
    "        xy = np.loadtxt('wine.csv', delimiter=',', dtype=np.float32, skiprows=1)\n",
    "        self.n_samples = xy.shape[0]\n",
    "\n",
    "        # here the first column is the class label, the rest are the features\n",
    "        self.x_data = torch.from_numpy(xy[:, 1:]) # size [n_samples, n_features]\n",
    "        self.y_data = torch.from_numpy(xy[:, [0]]) # size [n_samples, 1]\n",
    "\n",
    "    # support indexing such that dataset[i] can be used to get i-th sample\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "\n",
    "    # we can call len(dataset) to return the size\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "\n",
    "\n",
    "# create dataset\n",
    "dataset = WineDataset()\n",
    "\n",
    "# get first sample and unpack\n",
    "first_data = dataset[0]\n",
    "features, labels = first_data\n",
    "print(features, labels)\n",
    "\n",
    "# Load whole dataset with DataLoader\n",
    "# shuffle: shuffle data, good for training\n",
    "# num_workers: faster loading as it uses multiple subprocesses\n",
    "# !!! IF YOU GET AN ERROR DURING LOADING, SET num_workers TO 0 !!!\n",
    "train_loader = DataLoader(dataset=dataset,\n",
    "                          batch_size=4,\n",
    "                          shuffle=True,\n",
    "                          num_workers=0)\n",
    "\n",
    "# convert to an iterator and look at one random sample\n",
    "dataiter = iter(train_loader)\n",
    "data = next(dataiter)\n",
    "features, labels = data\n",
    "print(features, labels)\n",
    "\n",
    "# Dummy Training loop\n",
    "num_epochs = 2\n",
    "total_samples = len(dataset)\n",
    "n_iterations = math.ceil(total_samples/4)\n",
    "print(total_samples, n_iterations)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        \n",
    "        # here: 178 samples, batch_size = 4, n_iters=178/4=44.5 -> 45 iterations\n",
    "        # Run your training process\n",
    "        if (i+1) % 5 == 0:\n",
    "            print(f'Epoch: {epoch+1}/{num_epochs}, Step {i+1}/{n_iterations}| Inputs {inputs.shape} | Labels {labels.shape}')\n",
    "\n",
    "# some famous datasets are available in torchvision.datasets\n",
    "# e.g. MNIST, Fashion-MNIST, CIFAR10, COCO\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', \n",
    "                                           train=True, \n",
    "                                           transform=torchvision.transforms.ToTensor(),  \n",
    "                                           download=True)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=3, \n",
    "                                           shuffle=True)\n",
    "\n",
    "# look at one random sample\n",
    "dataiter = iter(train_loader)\n",
    "data = next(dataiter)\n",
    "inputs, targets = data\n",
    "print(inputs.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nIt looks like there's a small typo in your question. You probably meant `__getitem__(self, index)`. This method is a special method in \\nPython classes, and it's used to implement the behavior of indexing, slicing, and iteration for objects. When you define this method in \\na class, you enable instances of that class to use square bracket notation (`[]`) to access elements.\\n\\nHere's a simple example to illustrate how `__getitem__` works:\\n\\n```python\\nclass MyList:\\n    def __init__(self, data):\\n        self.data = data\\n\\n    def __getitem__(self, index):\\n        return self.data[index]\\n\\nmy_list = MyList([1, 2, 3, 4, 5])\\n\\n# Now, you can use square bracket notation to access elements\\nprint(my_list[2])  # Output: 3\\n```\\n\\nIn this example, `__getitem__` is defined to return the element at the specified index in the `data` list. By doing this, instances of the\\n `MyList` class can be treated like regular Python lists when it comes to indexing.\\n\\nThis method is commonly used in classes that represent collections of data (such as lists or arrays) to provide a way to access elements in \\na manner similar to built-in Python sequences.\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "__getitem__(self, index) is a special method in Python classes, and it's used to implement the behavior of indexing, slicing, and iteration \n",
    "for objects. When you define this method in a class, you enable instances of that class to use square bracket notation (`[]`) to access \n",
    "elements.\n",
    "\n",
    "Here's a simple example to illustrate how `__getitem__` works:\n",
    "\n",
    "```python\n",
    "class MyList:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "\n",
    "my_list = MyList([1, 2, 3, 4, 5])\n",
    "\n",
    "# Now, you can use square bracket notation to access elements\n",
    "print(my_list[2])  # Output: 3\n",
    "```\n",
    "\n",
    "In this example, `__getitem__` is defined to return the element at the specified index in the `data` list. By doing this, instances of the\n",
    " `MyList` class can be treated like regular Python lists when it comes to indexing.\n",
    "\n",
    "This method is commonly used in classes that represent collections of data (such as lists or arrays) to provide a way to access elements in \n",
    "a manner similar to built-in Python sequences.\n",
    "'''\n",
    "\n",
    "\n",
    "'''\n",
    "The `__len__` method is another special method in Python classes. It is used to define the behavior of the built-in `len()` function \n",
    "when applied to an object. By implementing `__len__` in a class, you specify the number of elements or the size of the object, allowing \n",
    "instances of that class to be used with the `len()` function.\n",
    "\n",
    "Here's a simple example:\n",
    "\n",
    "```python\n",
    "class MyList:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "my_list = MyList([1, 2, 3, 4, 5])\n",
    "\n",
    "# Now, you can use the len() function with instances of MyList\n",
    "print(len(my_list))  # Output: 5\n",
    "```\n",
    "\n",
    "In this example, the `__len__` method is defined to return the length of the `data` list. As a result, when you use the `len()` function \n",
    "with an instance of the `MyList` class, it returns the length of the underlying data.\n",
    "\n",
    "Implementing `__len__` is particularly useful when you create custom classes that represent collections, as it allows you to leverage \n",
    "Python's built-in functions and conventions for working with such objects.\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
