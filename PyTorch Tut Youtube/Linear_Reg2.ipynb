{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before training : f(5) =  tensor(0., grad_fn=<MulBackward0>)\n",
      "epoch 1 : w =  0.29999998211860657  loss =  30.0\n",
      "epoch 2 : w =  0.5549999475479126  loss =  21.674999237060547\n",
      "epoch 3 : w =  0.7717499136924744  loss =  15.660187721252441\n",
      "epoch 4 : w =  0.9559874534606934  loss =  11.314486503601074\n",
      "epoch 5 : w =  1.1125893592834473  loss =  8.17471694946289\n",
      "epoch 6 : w =  1.2457009553909302  loss =  5.9062323570251465\n",
      "epoch 7 : w =  1.358845829963684  loss =  4.2672529220581055\n",
      "epoch 8 : w =  1.4550189971923828  loss =  3.083089828491211\n",
      "epoch 9 : w =  1.5367661714553833  loss =  2.227532148361206\n",
      "epoch 10 : w =  1.6062512397766113  loss =  1.609391689300537\n",
      "epoch 11 : w =  1.6653136014938354  loss =  1.1627856492996216\n",
      "epoch 12 : w =  1.7155165672302246  loss =  0.8401124477386475\n",
      "epoch 13 : w =  1.758189082145691  loss =  0.6069811582565308\n",
      "epoch 14 : w =  1.7944607734680176  loss =  0.4385439455509186\n",
      "epoch 15 : w =  1.825291633605957  loss =  0.3168478012084961\n",
      "epoch 16 : w =  1.8514978885650635  loss =  0.22892260551452637\n",
      "epoch 17 : w =  1.873773217201233  loss =  0.1653965264558792\n",
      "epoch 18 : w =  1.8927072286605835  loss =  0.11949898302555084\n",
      "epoch 19 : w =  1.9088011980056763  loss =  0.08633805811405182\n",
      "epoch 20 : w =  1.9224810600280762  loss =  0.0623791441321373\n",
      "epoch 21 : w =  1.934108853340149  loss =  0.0450688973069191\n",
      "epoch 22 : w =  1.9439924955368042  loss =  0.03256231173872948\n",
      "epoch 23 : w =  1.952393651008606  loss =  0.02352631464600563\n",
      "epoch 24 : w =  1.9595346450805664  loss =  0.016997724771499634\n",
      "epoch 25 : w =  1.9656044244766235  loss =  0.012280836701393127\n",
      "epoch 26 : w =  1.9707638025283813  loss =  0.008872910402715206\n",
      "epoch 27 : w =  1.9751492738723755  loss =  0.0064106592908501625\n",
      "epoch 28 : w =  1.9788768291473389  loss =  0.004631685093045235\n",
      "epoch 29 : w =  1.982045292854309  loss =  0.0033464201260358095\n",
      "epoch 30 : w =  1.9847384691238403  loss =  0.0024177832528948784\n",
      "epoch 31 : w =  1.987027645111084  loss =  0.0017468547448515892\n",
      "epoch 32 : w =  1.9889734983444214  loss =  0.0012621148489415646\n",
      "epoch 33 : w =  1.9906275272369385  loss =  0.0009118800517171621\n",
      "epoch 34 : w =  1.9920333623886108  loss =  0.0006588209653273225\n",
      "epoch 35 : w =  1.9932283163070679  loss =  0.0004760062729474157\n",
      "epoch 36 : w =  1.99424409866333  loss =  0.00034391897497698665\n",
      "epoch 37 : w =  1.9951075315475464  loss =  0.0002484779979567975\n",
      "epoch 38 : w =  1.995841383934021  loss =  0.00017952272901311517\n",
      "epoch 39 : w =  1.9964652061462402  loss =  0.00012970640091225505\n",
      "epoch 40 : w =  1.996995449066162  loss =  9.371075429953635e-05\n",
      "epoch 41 : w =  1.9974461793899536  loss =  6.770494655938819e-05\n",
      "epoch 42 : w =  1.9978291988372803  loss =  4.891453863820061e-05\n",
      "epoch 43 : w =  1.998154878616333  loss =  3.5343608033144847e-05\n",
      "epoch 44 : w =  1.99843168258667  loss =  2.5532886866130866e-05\n",
      "epoch 45 : w =  1.9986668825149536  loss =  1.844714643084444e-05\n",
      "epoch 46 : w =  1.9988667964935303  loss =  1.3328777640708722e-05\n",
      "epoch 47 : w =  1.9990367889404297  loss =  9.631531611375976e-06\n",
      "epoch 48 : w =  1.9991812705993652  loss =  6.958316589589231e-06\n",
      "epoch 49 : w =  1.9993040561676025  loss =  5.027383849665057e-06\n",
      "epoch 50 : w =  1.999408483505249  loss =  3.632284688137588e-06\n",
      "epoch 51 : w =  1.9994971752166748  loss =  2.6243997126584873e-06\n",
      "epoch 52 : w =  1.9995726346969604  loss =  1.8964256014442071e-06\n",
      "epoch 53 : w =  1.9996367692947388  loss =  1.3698846714760293e-06\n",
      "epoch 54 : w =  1.9996912479400635  loss =  9.894590675685322e-07\n",
      "epoch 55 : w =  1.9997375011444092  loss =  7.148483405217121e-07\n",
      "epoch 56 : w =  1.999776840209961  loss =  5.168862458049261e-07\n",
      "epoch 57 : w =  1.9998103380203247  loss =  3.7350218917708844e-07\n",
      "epoch 58 : w =  1.9998388290405273  loss =  2.697535705920018e-07\n",
      "epoch 59 : w =  1.9998630285263062  loss =  1.9482058633002453e-07\n",
      "epoch 60 : w =  1.9998835325241089  loss =  1.4073337695208465e-07\n",
      "epoch 61 : w =  1.9999010562896729  loss =  1.0175587306093803e-07\n",
      "epoch 62 : w =  1.9999158382415771  loss =  7.338856278238381e-08\n",
      "epoch 63 : w =  1.9999284744262695  loss =  5.315412465733971e-08\n",
      "epoch 64 : w =  1.999939203262329  loss =  3.836930773104541e-08\n",
      "epoch 65 : w =  1.999948263168335  loss =  2.7700096438820765e-08\n",
      "epoch 66 : w =  1.9999560117721558  loss =  2.0093764874218323e-08\n",
      "epoch 67 : w =  1.999962568283081  loss =  1.4520100677373193e-08\n",
      "epoch 68 : w =  1.99996817111969  loss =  1.0521901572246861e-08\n",
      "epoch 69 : w =  1.999972939491272  loss =  7.592394268840508e-09\n",
      "epoch 70 : w =  1.9999769926071167  loss =  5.487198251330483e-09\n",
      "epoch 71 : w =  1.9999804496765137  loss =  3.9741685498029256e-09\n",
      "epoch 72 : w =  1.9999834299087524  loss =  2.866613613150548e-09\n",
      "epoch 73 : w =  1.999985933303833  loss =  2.0563000191486935e-09\n",
      "epoch 74 : w =  1.999988079071045  loss =  1.479023126194079e-09\n",
      "epoch 75 : w =  1.9999898672103882  loss =  1.0658141036401503e-09\n",
      "epoch 76 : w =  1.9999914169311523  loss =  7.718661265698756e-10\n",
      "epoch 77 : w =  1.9999927282333374  loss =  5.525180313270539e-10\n",
      "epoch 78 : w =  1.9999938011169434  loss =  3.978932738846197e-10\n",
      "epoch 79 : w =  1.9999947547912598  loss =  2.8819613362429664e-10\n",
      "epoch 80 : w =  1.9999955892562866  loss =  2.063416104647331e-10\n",
      "epoch 81 : w =  1.999996304512024  loss =  1.4670220593870908e-10\n",
      "epoch 82 : w =  1.9999969005584717  loss =  1.0176748332924035e-10\n",
      "epoch 83 : w =  1.9999973773956299  loss =  7.317169092857512e-11\n",
      "epoch 84 : w =  1.9999977350234985  loss =  5.0661697059695143e-11\n",
      "epoch 85 : w =  1.9999980926513672  loss =  3.807443249570497e-11\n",
      "epoch 86 : w =  1.9999983310699463  loss =  2.7284841053187847e-11\n",
      "epoch 87 : w =  1.9999985694885254  loss =  2.0307311388023663e-11\n",
      "epoch 88 : w =  1.9999988079071045  loss =  1.5347723092418164e-11\n",
      "epoch 89 : w =  1.9999990463256836  loss =  1.1098677532572765e-11\n",
      "epoch 90 : w =  1.9999991655349731  loss =  6.821210263296962e-12\n",
      "epoch 91 : w =  1.9999992847442627  loss =  5.076827847005916e-12\n",
      "epoch 92 : w =  1.9999994039535522  loss =  3.595346242946107e-12\n",
      "epoch 93 : w =  1.9999995231628418  loss =  2.7746693831431912e-12\n",
      "epoch 94 : w =  1.9999996423721313  loss =  1.7053025658242404e-12\n",
      "epoch 95 : w =  1.9999996423721313  loss =  8.988365607365267e-13\n",
      "epoch 96 : w =  1.9999996423721313  loss =  8.988365607365267e-13\n",
      "epoch 97 : w =  1.9999996423721313  loss =  8.988365607365267e-13\n",
      "epoch 98 : w =  1.9999996423721313  loss =  8.988365607365267e-13\n",
      "epoch 99 : w =  1.9999996423721313  loss =  8.988365607365267e-13\n",
      "epoch 100 : w =  1.9999996423721313  loss =  8.988365607365267e-13\n",
      "Prediction after training : f(5) =  9.999998092651367\n"
     ]
    }
   ],
   "source": [
    "x=torch.tensor([1,2,3,4], dtype=torch.float32)\n",
    "y=torch.tensor([2,4,6,8], dtype=torch.float32)\n",
    "\n",
    "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "#model prediction\n",
    "def forward(x):\n",
    "    return w*x\n",
    "\n",
    "#loss = MSE\n",
    "def loss(y, y_pred):\n",
    "    return ((y - y_pred)**2).mean()\n",
    "\n",
    "print(\"Prediction before training : f(5) = \",forward(5))\n",
    "\n",
    "# Training\n",
    "learning_rate = 0.01\n",
    "no_of_iters = 100\n",
    "\n",
    "\n",
    "for epoch in range(no_of_iters):\n",
    "    # Prediction\n",
    "    y_pred = forward(x)\n",
    "\n",
    "    # Loss\n",
    "    l = loss(y, y_pred)\n",
    "\n",
    "    # Gradients = backward pass\n",
    "    l.backward()\n",
    "    dw = w.grad\n",
    "\n",
    "    # Update weights\n",
    "    with torch.no_grad():\n",
    "        w -= learning_rate * dw\n",
    "\n",
    "    # Zero gradients\n",
    "    w.grad.zero_()\n",
    "\n",
    "    print(\"epoch\", epoch + 1, \": w = \", w.item(), \" loss = \", l.item())\n",
    "\n",
    "print(\"Prediction after training : f(5) = \", forward(5).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
