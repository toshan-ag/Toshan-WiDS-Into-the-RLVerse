{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.empty(3) #create an empty tensor\n",
    "print(x)\n",
    "\n",
    "x=torch.empty(2,3)\n",
    "print(x)\n",
    "\n",
    "x=torch.empty(2,2,3)\n",
    "print(x)\n",
    "\n",
    "x=torch.empty(2,2,2,3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.rand(2,3)\n",
    "print(x)\n",
    "\n",
    "x=torch.zeros(3,2)\n",
    "print(x)\n",
    "print(x.dtype) #gives datatype of the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#By Default, the datatype is float32.\n",
    "#But we can always assign a datatype to the tensor as follows\n",
    "x=torch.ones(2,3,dtype=torch.double) #Other dtypes are torch.int, torch.float16, etc\n",
    "print(x)\n",
    "print(x.dtype)\n",
    "print(x.size()) #returns size of the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating tensors from data\n",
    "x=torch.tensor([2.5,0.1,3]) #from list\n",
    "print(x)\n",
    "print(x.size())\n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.rand(2,3)\n",
    "y=torch.rand(2,3)\n",
    "print(x)\n",
    "print(y)\n",
    "z=x+y\n",
    "print(z)\n",
    "\n",
    "x=torch.rand(2,3)\n",
    "y=torch.rand(3,2)\n",
    "print(x)\n",
    "print(y)\n",
    "z=x+y\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.rand(2,3)\n",
    "y=torch.rand(2,3)\n",
    "print(x)\n",
    "print(y)\n",
    "z=torch.add(x,y) #same as z=x+y\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.rand(2,3)\n",
    "y=torch.rand(2,3)\n",
    "print(x)\n",
    "print(y)\n",
    "y.add_(x) #same as y=y+x\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.rand(2,3)\n",
    "y=torch.rand(2,3)\n",
    "print(x)\n",
    "print(y)\n",
    "z=torch.sub(x,y) #same as z=x-y\n",
    "print(z)\n",
    "z=torch.mul(x,y) #same as z=x*y\n",
    "print(z)\n",
    "z=torch.div(x,y) #same as z=x/y\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9133, 0.5448, 0.0954],\n",
      "        [0.9390, 0.2067, 0.1451],\n",
      "        [0.5356, 0.7338, 0.4305],\n",
      "        [0.8893, 0.5855, 0.4680],\n",
      "        [0.0415, 0.1799, 0.9745]])\n",
      "tensor([0.1451])\n",
      "tensor([0.5448, 0.2067, 0.7338, 0.5855, 0.1799])\n",
      "tensor([[0.9133, 0.5448],\n",
      "        [0.9390, 0.2067],\n",
      "        [0.5356, 0.7338],\n",
      "        [0.8893, 0.5855],\n",
      "        [0.0415, 0.1799]])\n",
      "0.20673322677612305\n"
     ]
    }
   ],
   "source": [
    "x=torch.rand(5,3)\n",
    "print(x)\n",
    "print(x[1,2:3])  #slicing of tensors\n",
    "print(x[:,1])\n",
    "print(x[:5,:2])\n",
    "\n",
    "print(x[1,1].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8227, 0.1837, 0.1123, 0.4316],\n",
      "        [0.4505, 0.2199, 0.3200, 0.5095],\n",
      "        [0.4429, 0.9919, 0.2892, 0.1542],\n",
      "        [0.2552, 0.4149, 0.3397, 0.4137]])\n",
      "torch.Size([4, 4])\n",
      "tensor([0.8227, 0.1837, 0.1123, 0.4316, 0.4505, 0.2199, 0.3200, 0.5095, 0.4429,\n",
      "        0.9919, 0.2892, 0.1542, 0.2552, 0.4149, 0.3397, 0.4137])\n",
      "torch.Size([16])\n",
      "tensor([[0.8227, 0.1837, 0.1123, 0.4316, 0.4505, 0.2199, 0.3200, 0.5095],\n",
      "        [0.4429, 0.9919, 0.2892, 0.1542, 0.2552, 0.4149, 0.3397, 0.4137]])\n",
      "torch.Size([2, 8])\n"
     ]
    }
   ],
   "source": [
    "#reshaping a tensor\n",
    "x=torch.rand(4,4) #implies that there are 4*4 = 16 values\n",
    "print(x)\n",
    "print(x.size())\n",
    "\n",
    "y=x.view(16) #total values = 16 (has to be same in both cases for re-shaping)\n",
    "print(y)\n",
    "print(y.size())\n",
    "\n",
    "z=x.view(-1,8) # put -1 if you don't know the dimension. pytorch can determine automatically\n",
    "print(z)\n",
    "print(z.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "[1. 1. 1. 1. 1.] <class 'numpy.ndarray'>\n",
      "tensor([2., 2., 2., 2., 2.])\n",
      "[1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "#torch to numpy array conversion\n",
    "a=torch.ones(5)\n",
    "print(a)\n",
    "\n",
    "b=a.numpy()\n",
    "print(b,type(b))\n",
    "\n",
    "a=a+1\n",
    "print(a)\n",
    "print(b) #b is unchanged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n",
      "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "#numpy array to torch conversion\n",
    "a=np.ones(5)\n",
    "print(a)\n",
    "\n",
    "b=torch.from_numpy(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Create a tensor filled with ones that does not track gradients\n",
    "x_no_grad = torch.ones(2, 2, requires_grad=False)\n",
    "print(x_no_grad)\n",
    "\n",
    "# Create a tensor filled with ones that tracks gradients\n",
    "x_with_grad = torch.ones(2, 2, requires_grad=True)\n",
    "print(x_with_grad)\n",
    "\n",
    "'''requires_grad parameter is an optional argument that you can pass to torch.ones() to specify whether the tensor should track operations \n",
    "for gradient computation. Gradients are essential for automatic differentiation, which is a key component in training neural networks using \n",
    "techniques like backpropagation.'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
